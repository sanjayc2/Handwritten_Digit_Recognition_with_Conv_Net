{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST with CNN and Data Augmentation and Regularization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGee2BGH8cslyP9lB8+ve0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjayc2/MNIST_w_CNN_NoOverfit_High_Accuracy/blob/main/MNIST_with_CNN_and_Data_Augmentation_and_Regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuDh-3xZ-GsW"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vsaNGtbl-YCv",
        "outputId": "6895e187-4a11-4727-8148-7180ad419400"
      },
      "source": [
        "keras.__version__\n",
        "tfds.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.0.1'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXu9TVlj-bY4",
        "outputId": "7282111c-2fa4-46aa-9aef-8adf5fb3ba5f"
      },
      "source": [
        "(X_train_full, y_train_full), (X_test_full, y_test_full) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov7J8RiR-l3m",
        "outputId": "3f4d9fca-fe3c-46d7-872f-d3cd9a8da5e9"
      },
      "source": [
        "X_train_full.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyxQz9Pfi3Sj",
        "outputId": "2172ab02-c77a-4c94-da26-d0bb8b6db5a0"
      },
      "source": [
        "X_train, X_valid = X_train_full[:50000]/255, X_train_full[50000:]/255\n",
        "y_train, y_valid = y_train_full[:50000], y_train_full[50000:]\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_valid.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000,)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAEgUfY-iHMV"
      },
      "source": [
        "# set up TensorBoard\n",
        "import os\n",
        "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
        "def get_run_logdir():\n",
        "  import time\n",
        "  run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "  return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe-g089mqkDr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt58t0IXrir0"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "n6JCAE4kxikD",
        "outputId": "fc4a8b23-4cc1-4c12-e251-5d290b8af830"
      },
      "source": [
        "pd.DataFrame(history.history).plot()\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-81acac14f299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYqenpTixzwA"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=5,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.05,\n",
        "    #zoom_range=[0.5,2],\n",
        "    validation_split=0.2,\n",
        "    )\n",
        "\n",
        "# reshape X_train and X_valid (4-dim tensors required)\n",
        "X_train_full = X_train_full.reshape(X_train_full.shape[0],X_train_full.shape[1],X_train_full.shape[2],1)\n",
        "\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(X_train_full)\n",
        "train_generator = datagen.flow(X_train_full, y_train_full, batch_size=32, shuffle=True, \n",
        "                               seed=42, save_to_dir=None, subset='training')\n",
        "\n",
        "validation_generator = datagen.flow(X_train_full, y_train_full, batch_size=32, shuffle=True, \n",
        "                               seed=42, save_to_dir=None, subset='validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfPyffQV0LuN"
      },
      "source": [
        "# define function for learning rate scheduler callback\n",
        "import keras.backend as K\n",
        "\n",
        "class lr_loss_callback(keras.callbacks.Callback):\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "        self.learn_rates = []\n",
        "        self.losses      = []\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if not hasattr(self.model.optimizer, \"lr\"):\n",
        "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
        "        if not hasattr(self.model.optimizer, \"iterations\"):\n",
        "            raise ValueError('Optimizer must have a \"iterations\" attribute.')\n",
        "        # Get the current learning rate from model's optimizer.\n",
        "        lr = float(K.get_value(self.model.optimizer.lr))\n",
        "        #if hasattr(self.model.optimizer, \"decay\"):\n",
        "        #  decay = self.model.optimizer.decay\n",
        "        #  iterations = self.model.optimizer.iterations \n",
        "        #  lr_updated = lr / (1. + decay * K.cast(iterations, K.dtype(decay)))\n",
        "        #else:\n",
        "        lr_updated = lr * self.factor  \n",
        "        self.learn_rates.append(lr_updated)\n",
        "        self.losses.append(logs[\"val_loss\"])\n",
        "        K.set_value(self.model.optimizer.lr, lr_updated)\n",
        "        print(\"\\nEpoch %05d: Learning rate is %6.4f.\" % (epoch, lr_updated))\n",
        "        print(\"The average validation loss for epoch {} is {:7.4f}\".format(epoch, logs[\"val_loss\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz4vn-Eke7w2"
      },
      "source": [
        "import numpy as np\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EECOzN-H14MO",
        "outputId": "388d508f-682b-4e04-8042-55f19b71c990"
      },
      "source": [
        "input_ = keras.layers.Input(shape=[28,28,1])\n",
        "flatten_ = keras.layers.Flatten()(input_)\n",
        "dropout1 = keras.layers.Dropout(rate=0.2)(flatten_)\n",
        "hidden1 = keras.layers.Dense(100, activation=\"relu\")(dropout1)\n",
        "dropout2 = keras.layers.Dropout(rate=0.1)(hidden1)\n",
        "hidden2 = keras.layers.Dense(50,activation=\"relu\")(dropout2)\n",
        "dropout3 = keras.layers.Dropout(rate=0.1)(hidden2)\n",
        "output = keras.layers.Dense(10,activation=\"softmax\")(dropout3)\n",
        "model = keras.Model(inputs = [input_], outputs = output)\n",
        "#model.save_weights('model.h5')\n",
        "optimizer = keras.optimizers.SGD(lr = 0.08)\n",
        "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "#model.load_weights('model.h5')\n",
        "lr_callback = lr_loss_callback(factor=1.00)    # dont change learning rate..\n",
        "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=10,\n",
        "    verbose=2,\n",
        "    mode=\"auto\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "history = model.fit(X_train, y_train, epochs = 100, validation_data=(X_valid, y_valid), callbacks=[lr_callback, early_stopping_callback])\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "#history = model.fit(train_generator, epochs=100, validation_data=validation_generator, callbacks=[lr_callback, early_stopping_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1548/1563 [============================>.] - ETA: 0s - loss: 0.4455 - accuracy: 0.8618\n",
            "Epoch 00000: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 0 is  0.1801\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 0.4440 - accuracy: 0.8623 - val_loss: 0.1801 - val_accuracy: 0.9472\n",
            "Epoch 2/100\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.2328 - accuracy: 0.9295\n",
            "Epoch 00001: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 1 is  0.1263\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2327 - accuracy: 0.9295 - val_loss: 0.1263 - val_accuracy: 0.9640\n",
            "Epoch 3/100\n",
            "1553/1563 [============================>.] - ETA: 0s - loss: 0.1888 - accuracy: 0.9425\n",
            "Epoch 00002: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 2 is  0.1100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1886 - accuracy: 0.9425 - val_loss: 0.1100 - val_accuracy: 0.9663\n",
            "Epoch 4/100\n",
            "1552/1563 [============================>.] - ETA: 0s - loss: 0.1606 - accuracy: 0.9507\n",
            "Epoch 00003: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 3 is  0.1062\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1608 - accuracy: 0.9507 - val_loss: 0.1062 - val_accuracy: 0.9675\n",
            "Epoch 5/100\n",
            "1555/1563 [============================>.] - ETA: 0s - loss: 0.1446 - accuracy: 0.9549\n",
            "Epoch 00004: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 4 is  0.1042\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1451 - accuracy: 0.9547 - val_loss: 0.1042 - val_accuracy: 0.9690\n",
            "Epoch 6/100\n",
            "1558/1563 [============================>.] - ETA: 0s - loss: 0.1353 - accuracy: 0.9581\n",
            "Epoch 00005: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 5 is  0.0807\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1355 - accuracy: 0.9580 - val_loss: 0.0807 - val_accuracy: 0.9773\n",
            "Epoch 7/100\n",
            "1545/1563 [============================>.] - ETA: 0s - loss: 0.1218 - accuracy: 0.9618\n",
            "Epoch 00006: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 6 is  0.0799\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1219 - accuracy: 0.9618 - val_loss: 0.0799 - val_accuracy: 0.9755\n",
            "Epoch 8/100\n",
            "1554/1563 [============================>.] - ETA: 0s - loss: 0.1158 - accuracy: 0.9625\n",
            "Epoch 00007: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 7 is  0.0838\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1158 - accuracy: 0.9625 - val_loss: 0.0838 - val_accuracy: 0.9756\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9648\n",
            "Epoch 00008: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 8 is  0.0724\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1098 - accuracy: 0.9648 - val_loss: 0.0724 - val_accuracy: 0.9782\n",
            "Epoch 10/100\n",
            "1548/1563 [============================>.] - ETA: 0s - loss: 0.1018 - accuracy: 0.9674\n",
            "Epoch 00009: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 9 is  0.0724\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1014 - accuracy: 0.9675 - val_loss: 0.0724 - val_accuracy: 0.9780\n",
            "Epoch 11/100\n",
            "1556/1563 [============================>.] - ETA: 0s - loss: 0.0987 - accuracy: 0.9683\n",
            "Epoch 00010: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 10 is  0.0710\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0986 - accuracy: 0.9684 - val_loss: 0.0710 - val_accuracy: 0.9783\n",
            "Epoch 12/100\n",
            "1549/1563 [============================>.] - ETA: 0s - loss: 0.0951 - accuracy: 0.9689\n",
            "Epoch 00011: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 11 is  0.0697\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0951 - accuracy: 0.9689 - val_loss: 0.0697 - val_accuracy: 0.9790\n",
            "Epoch 13/100\n",
            "1557/1563 [============================>.] - ETA: 0s - loss: 0.0943 - accuracy: 0.9705\n",
            "Epoch 00012: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 12 is  0.0739\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0942 - accuracy: 0.9705 - val_loss: 0.0739 - val_accuracy: 0.9773\n",
            "Epoch 14/100\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 0.0895 - accuracy: 0.9712\n",
            "Epoch 00013: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 13 is  0.0728\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0895 - accuracy: 0.9712 - val_loss: 0.0728 - val_accuracy: 0.9791\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9718\n",
            "Epoch 00014: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 14 is  0.0697\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0863 - accuracy: 0.9718 - val_loss: 0.0697 - val_accuracy: 0.9793\n",
            "Epoch 16/100\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 0.0849 - accuracy: 0.9723\n",
            "Epoch 00015: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 15 is  0.0678\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0848 - accuracy: 0.9723 - val_loss: 0.0678 - val_accuracy: 0.9804\n",
            "Epoch 17/100\n",
            "1552/1563 [============================>.] - ETA: 0s - loss: 0.0821 - accuracy: 0.9736\n",
            "Epoch 00016: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 16 is  0.0693\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0823 - accuracy: 0.9735 - val_loss: 0.0693 - val_accuracy: 0.9793\n",
            "Epoch 18/100\n",
            "1549/1563 [============================>.] - ETA: 0s - loss: 0.0827 - accuracy: 0.9733\n",
            "Epoch 00017: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 17 is  0.0656\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0827 - accuracy: 0.9733 - val_loss: 0.0656 - val_accuracy: 0.9808\n",
            "Epoch 19/100\n",
            "1544/1563 [============================>.] - ETA: 0s - loss: 0.0790 - accuracy: 0.9745\n",
            "Epoch 00018: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 18 is  0.0699\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0790 - accuracy: 0.9746 - val_loss: 0.0699 - val_accuracy: 0.9783\n",
            "Epoch 20/100\n",
            "1558/1563 [============================>.] - ETA: 0s - loss: 0.0773 - accuracy: 0.9747\n",
            "Epoch 00019: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 19 is  0.0668\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0775 - accuracy: 0.9746 - val_loss: 0.0668 - val_accuracy: 0.9797\n",
            "Epoch 21/100\n",
            "1549/1563 [============================>.] - ETA: 0s - loss: 0.0736 - accuracy: 0.9755\n",
            "Epoch 00020: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 20 is  0.0696\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0743 - accuracy: 0.9754 - val_loss: 0.0696 - val_accuracy: 0.9800\n",
            "Epoch 22/100\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.0757 - accuracy: 0.9754\n",
            "Epoch 00021: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 21 is  0.0668\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0756 - accuracy: 0.9754 - val_loss: 0.0668 - val_accuracy: 0.9797\n",
            "Epoch 23/100\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.0737 - accuracy: 0.9762\n",
            "Epoch 00022: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 22 is  0.0682\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0737 - accuracy: 0.9762 - val_loss: 0.0682 - val_accuracy: 0.9807\n",
            "Epoch 24/100\n",
            "1554/1563 [============================>.] - ETA: 0s - loss: 0.0734 - accuracy: 0.9762\n",
            "Epoch 00023: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 23 is  0.0663\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0733 - accuracy: 0.9762 - val_loss: 0.0663 - val_accuracy: 0.9816\n",
            "Epoch 25/100\n",
            "1551/1563 [============================>.] - ETA: 0s - loss: 0.0694 - accuracy: 0.9770\n",
            "Epoch 00024: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 24 is  0.0717\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0692 - accuracy: 0.9771 - val_loss: 0.0717 - val_accuracy: 0.9795\n",
            "Epoch 26/100\n",
            "1553/1563 [============================>.] - ETA: 0s - loss: 0.0689 - accuracy: 0.9774\n",
            "Epoch 00025: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 25 is  0.0677\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0688 - accuracy: 0.9774 - val_loss: 0.0677 - val_accuracy: 0.9800\n",
            "Epoch 27/100\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 0.0693 - accuracy: 0.9776\n",
            "Epoch 00026: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 26 is  0.0699\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0693 - accuracy: 0.9776 - val_loss: 0.0699 - val_accuracy: 0.9796\n",
            "Epoch 28/100\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 0.0680 - accuracy: 0.9774\n",
            "Epoch 00027: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 27 is  0.0651\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0679 - accuracy: 0.9775 - val_loss: 0.0651 - val_accuracy: 0.9807\n",
            "Epoch 29/100\n",
            "1555/1563 [============================>.] - ETA: 0s - loss: 0.0659 - accuracy: 0.9786\n",
            "Epoch 00028: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 28 is  0.0670\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0658 - accuracy: 0.9786 - val_loss: 0.0670 - val_accuracy: 0.9810\n",
            "Epoch 30/100\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.0667 - accuracy: 0.9777\n",
            "Epoch 00029: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 29 is  0.0713\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0667 - accuracy: 0.9777 - val_loss: 0.0713 - val_accuracy: 0.9800\n",
            "Epoch 31/100\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 0.0652 - accuracy: 0.9787\n",
            "Epoch 00030: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 30 is  0.0677\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0653 - accuracy: 0.9787 - val_loss: 0.0677 - val_accuracy: 0.9794\n",
            "Epoch 32/100\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 0.0611 - accuracy: 0.9798\n",
            "Epoch 00031: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 31 is  0.0687\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0611 - accuracy: 0.9798 - val_loss: 0.0687 - val_accuracy: 0.9798\n",
            "Epoch 33/100\n",
            "1549/1563 [============================>.] - ETA: 0s - loss: 0.0647 - accuracy: 0.9790\n",
            "Epoch 00032: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 32 is  0.0664\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0649 - accuracy: 0.9789 - val_loss: 0.0664 - val_accuracy: 0.9799\n",
            "Epoch 34/100\n",
            "1546/1563 [============================>.] - ETA: 0s - loss: 0.0612 - accuracy: 0.9803\n",
            "Epoch 00033: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 33 is  0.0688\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0611 - accuracy: 0.9803 - val_loss: 0.0688 - val_accuracy: 0.9802\n",
            "Epoch 35/100\n",
            "1545/1563 [============================>.] - ETA: 0s - loss: 0.0617 - accuracy: 0.9791\n",
            "Epoch 00034: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 34 is  0.0668\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0617 - accuracy: 0.9791 - val_loss: 0.0668 - val_accuracy: 0.9806\n",
            "Epoch 36/100\n",
            "1556/1563 [============================>.] - ETA: 0s - loss: 0.0619 - accuracy: 0.9800\n",
            "Epoch 00035: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 35 is  0.0657\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0619 - accuracy: 0.9800 - val_loss: 0.0657 - val_accuracy: 0.9813\n",
            "Epoch 37/100\n",
            "1556/1563 [============================>.] - ETA: 0s - loss: 0.0581 - accuracy: 0.9807\n",
            "Epoch 00036: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 36 is  0.0718\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0580 - accuracy: 0.9807 - val_loss: 0.0718 - val_accuracy: 0.9794\n",
            "Epoch 38/100\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.0594 - accuracy: 0.9807\n",
            "Epoch 00037: Learning rate is 0.0800.\n",
            "The average validation loss for epoch 37 is  0.0675\n",
            "Restoring model weights from the end of the best epoch: 28.\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0594 - accuracy: 0.9807 - val_loss: 0.0675 - val_accuracy: 0.9803\n",
            "Epoch 00038: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "KseavEPIgx_H",
        "outputId": "452a3c85-b2ae-469e-b80b-ec35313dc4b0"
      },
      "source": [
        "X_test = X_test_full\n",
        "Y_test = Y_test_full\n",
        "model.evaluate(X_test, y_test)\n",
        "y_pred = model.predict(X_test)\n",
        "#print(type(y_pred.argmax()))\n",
        "#print(type(y_test))\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_matrix = confusion_matrix(y_test, np.argmax(y_pred,axis=1))\n",
        "print(\"conf_matrix:\", conf_matrix)\n",
        "\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1)\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6d92b607da6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test_full\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_test_full\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(type(y_pred.argmax()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test_full' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "jAJytB2UmBuT",
        "outputId": "268ad813-164a-4fa0-a2fe-19ee758b38ce"
      },
      "source": [
        "plt.plot(lr_loss_update.learn_rates, lr_loss_update.losses)\n",
        "plt.gca().set_xscale('log')\n",
        "plt.hlines(min(lr_loss_update.losses), min(lr_loss_update.learn_rates), max(lr_loss_update.learn_rates))\n",
        "plt.axis([min(lr_loss_update.learn_rates), max(lr_loss_update.learn_rates), 0, lr_loss_update.losses[0]])\n",
        "plt.grid()\n",
        "plt.xlabel(\"Learning rate\")\n",
        "plt.ylabel(\"Loss\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c437721713cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_loss_update\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_rates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_loss_update\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_loss_update\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_loss_update\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_rates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_loss_update\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_rates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_loss_update\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_rates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_loss_update\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_rates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_loss_update\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lr_loss_update' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "hhaTJliZzW2g",
        "outputId": "df951e71-81b1-428b-d614-47dbf4543eed"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-15b1e9f041d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlr_callaback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0D5PhsnzuJQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}